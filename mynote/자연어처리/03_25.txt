10. 자연어 처리
[1] NLTK 패키지
-텍스트 마이닝: 자연어에서 의미 있는 정보를 찾는 것
>비정형 문서 데이터로부터 문서별 단어의 행렬을 만든 후 기법을 통해 통찰을 얻거나 의사결정을 지원
>주요기능: 말뭉치, 토큰 생성, 형태소 분석, 품사 태깅

ex)
import nltk
nltk.download()
from nltk.book import *
nltk.corpus.gutenberg.fileids() #말뭉치 리스트
emma = nltk.corpus.gutenberg.raw('austen-emma.txt') #emma라는 소설 가져오기

from nltk.tokenize import sent_tokenize > 문자열을 받아 문장 단위로 리스트 출력
sent_tokens = sent_tokenize(emma)
print(len(sent_tokens))

from nltk.tokenize import word_tokenize# 단어 단위로 분류
word_tokens = word_tokenize(emma)
print(len(word_tokens))

from nltk.tokenize import RegexpTokenizer #토큰화할 때 정규표현식 이용
ret = RegexpTokenizer('[\w]+')
print(ret.tokenize(sent_tokens[0]))

[2]형태소 분석
:의미가 있는 가장 작은 말의 단위
- stemming: 어간 추출
- lemmatizing: 원형 복원
- part of speech tagging: 품사 태깅
 
ex)
#어간 추출1: ParterStr
from nltk.stem import PorterStemmer
pst = PorterStemmer()

#어간 추출2: LancasterStemmer
from nltk.stem import LancasterStemmer
lst = LancasterStemmer()

#어간 추출3: RegexpStemmer
from nltk.stem import RegexpStemmer
rst = RegexpStemmer('ing')

#원형 복원
from nltk.stem.wordnet import WordNetLemmatizer
wl = WordNetLemmatizer()
[wl.lemmatize(word) for word in words2]

#품사 태깅
from nltk.tag import pos_tag
tagged_list = pos_tag(word_tokenize(sent_tokens[10]))
print(word_tokenize(sent_tokens[10]))

#Text(): 지정한 단어가 얼마나 많이 나타날지 단어의 위치를 표시
from nltk import Text
emma_test = Text(words)

[3] 한글 형태소 분석
1) 자연어 처리
- 자연어: 사람들이 일상적으로 사용하는 언어
- 자연어 처리하는 분야
    - 자연어 이해: 형태소 분석 > 의미 분석 > 대화 분석
    - 자연어 생성: 대화 분석 > 다음 문장이나 단어 출력
- 활용 분야: 맞춤법 검사, 번역기, 키워드 분석

2) 형태소 분석 절차
- 전처리: 단어, 어절 추출
- 분석 후보 생성: 형태소 분리, 품사 태깅, 원형 복원
- 제약 조건 규칙 확인
- 분석

3) 한글 형태소 분석 엔진
- KoNLPy: 파이썬용 > ! pip install JPype1-1.2.0-cp38-cp38-win_amd64.whl
- KOMORAN: 자바로 만든 형태소 분석기(JAVA_HOME 시스템 변수)
- HanNanum: 자바로 만든 형태소 분석기(JAVA_HOME 시스템 변수)
- Kkma: 서울대학교
- KoNLP: R용